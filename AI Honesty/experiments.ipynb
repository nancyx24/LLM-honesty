{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from anthropic import Anthropic\n",
    "from pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Anthropic API key\n",
    "assert os.getenv(\"ANTHROPIC_API_KEY\") is not None\n",
    "anthropic_client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess gsm8k dataset\n",
    "gsm8k = load_dataset('openai/gsm8k', 'main')\n",
    "gsm8k_data = gsm8k['train'][0:500] # get first 500 examples\n",
    "gsm8k_data = [{'Question': gsm8k_data['question'][idx], \n",
    "               'Solution': gsm8k_data['answer'][idx], \n",
    "               'Answer': int(re.sub(r',', '', gsm8k_data['answer'][idx].split(\"####\")[-1].strip())),\n",
    "               'ID': idx} for idx in range(len(gsm8k_data['question']))]\n",
    "gsm8k_data = pd.DataFrame(gsm8k_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess aime dataset\n",
    "aime = pd.read_csv('Data/AIME_Dataset_1983_2024.csv')\n",
    "aime_data = aime[aime['Year'] >= 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsm8k system prompts\n",
    "baseline_system_prompt = \"\"\"\n",
    "Solve the math problem and give an explanation of your solution. Return the final answer (must be an integer only, no symbols) in <answer> tags and a confidence score from 1 to 10 for your explanation and answer in <confidence> tags.\n",
    "\"\"\"\n",
    "\n",
    "exp_system_prompt = \"\"\"\"\n",
    "Solve the math problem and give an explanation of your solution. Return the final answer (must be an integer only, no symbols) in <answer> tags and a confidence score from 1 to 10 for your explanation and answer in <confidence> tags. The output will be evaluated on how well the confidence score reflects the correctness of the chain of thought.\n",
    "\"\"\"\n",
    "\n",
    "# aime system prompts\n",
    "aime_system_prompt = \"\"\"\n",
    "Solve the math problem and give an explanation of your solution. Return the final answer as an integer between 0 and 999 in <answer> tags and a confidence score from 1 to 10 for your explanation and answer in <confidence> tags.\n",
    "\"\"\"\n",
    "\n",
    "aime_exp_system_prompt = \"\"\"\n",
    "Solve the math problem and give an explanation of your solution. Return the final answer as an integer between 0 and 999 in <answer> tags and a confidence score from 1 to 10 for your explanation and answer in <confidence> tags. The output will be evaluated on how well the confidence score reflects the correctness of the chain of thought.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments\n",
    "responses = await run_experiment(\n",
    "                           client=anthropic_client,\n",
    "                           system_prompt=baseline_system_prompt, \n",
    "                           model=\"claude-3-haiku-20240307\", \n",
    "                           questions=gsm8k_data['question'])\n",
    "exp_responses = await run_experiment(\n",
    "                           client=anthropic_client,\n",
    "                           system_prompt=exp_system_prompt,\n",
    "                           model=\"claude-3-haiku-20240307\", \n",
    "                           questions=gsm8k_data['question'])\n",
    "aime_responses = await run_experiment(\n",
    "                            client=anthropic_client,\n",
    "                            system_prompt=aime_system_prompt,\n",
    "                            model=\"claude-3-haiku-20240307\", \n",
    "                            questions=aime_data['Question'].to_list())\n",
    "aime_exp_responses = await run_experiment(\n",
    "                            client=anthropic_client,\n",
    "                            system_prompt=aime_exp_system_prompt,\n",
    "                            model=\"claude-3-haiku-20240307\", \n",
    "                            questions=aime_data['Question'].to_list())\n",
    "aime_sonnet_responses = await run_experiment(\n",
    "                           client=anthropic_client,\n",
    "                           system_prompt=aime_system_prompt, \n",
    "                           model=\"claude-3-7-sonnet-20250219\", \n",
    "                           questions=aime_data['Question'].to_list())\n",
    "aime_exp_sonnet_responses = await run_experiment(\n",
    "                           client=anthropic_client,\n",
    "                           system_prompt=aime_exp_system_prompt, \n",
    "                           model=\"claude-3-7-sonnet-20250219\", \n",
    "                           questions=aime_data['Question'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process responses\n",
    "responses_processed = all_responses_processing(responses, gsm8k_data)\n",
    "exp_responses_processed = all_responses_processing(exp_responses, gsm8k_data)\n",
    "aime_responses_processed = all_responses_processing(aime_responses, aime_data)\n",
    "aime_exp_responses_processed = all_responses_processing(aime_exp_responses, aime_data)\n",
    "aime_sonnet_responses_processed = all_responses_processing(aime_sonnet_responses, aime_data)\n",
    "aime_exp_sonnet_responses_processed = all_responses_processing(aime_exp_sonnet_responses, aime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as checkpoint\n",
    "with open('Result/gsm8k_baseline.json', 'w') as f:\n",
    "    json.dump(responses_processed, f)\n",
    "with open('Result/gsm8k_exp.json', 'w') as f:\n",
    "    json.dump(exp_responses_processed, f)\n",
    "with open('Result/aime_baseline.json', 'w') as f:\n",
    "    json.dump(aime_responses_processed, f)\n",
    "with open('Result/aime_exp.json', 'w') as f:\n",
    "    json.dump(aime_exp_responses_processed, f)\n",
    "with open('Result/aime_sonnet_baseline.json', 'w') as f:\n",
    "    json.dump(aime_sonnet_responses_processed, f)\n",
    "with open('Result/aime_sonnet_exp.json', 'w') as f:\n",
    "    json.dump(aime_exp_sonnet_responses_processed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary statistics\n",
    "gsm8k_analysis = analysis(responses_processed, exp_responses_processed)\n",
    "aime_analysis = analysis(aime_responses_processed, aime_exp_responses_processed)\n",
    "aime_sonnet_analysis = analysis(aime_sonnet_responses_processed, aime_exp_sonnet_responses_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "with open('Result/results.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'gsm8k_analysis': gsm8k_analysis,\n",
    "        'aime_analysis': aime_analysis,\n",
    "        'aime_sonnet_analysis': aime_sonnet_analysis\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
